# nibblecompress
Short Data Compression Algorithm

This work deals with the algorithm of data compression, of the codification of the same in a differentiated way with a removal of its redundancies, thus reducing the space required for its storage and the time necessary for its transmission without changing the meaning of the information, we also consider the short data, where redundancy is little or nonexistent, as well as a compression ratio of the current algorithms, which is lower or negative, that is, the result of the compression is greater than the original data. With this scenario we have as general objective of the research an analysis and implementation of the algorithm "Nibble Compress" and its unfolding in applications; and, as specific objectives we have an analysis of the representation of the data entropy; The records of conditions for short sequences in data algorithms; A literature review in the area. To consolidate these objectives, a literature review methodology should be used in a documentary and historical manner on the subject. With this it is as if it were a machine, the half-byte (nibble) is used as the source alphabet code and generating a minimum redundancy binary with a Huffman coding to propose, with this, an algorithm with a better compression rate in tablets compared to already established algorithms, thus obtaining an average compression ratio of 13,23% while the state-of-the-art algorithms have a mean of -36,06%. Finally, the author suggests a commentary on the topic, as well as an analysis of trends and mega-tendencies.
